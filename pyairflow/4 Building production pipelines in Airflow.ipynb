{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Building production pipelines in Airflow\n",
    "Use what you've learned to build a production quality workflow in Airflow."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a templated BashOperator\n",
    "You've successfully created a BashOperator that cleans a given data file by executing a script called cleandata.sh. This works, but unfortunately requires the script to be run only for the current day. Some of your data sources are occasionally behind by a couple of days and need to be run manually.\n",
    "\n",
    "You successfully modify the cleandata.sh script to take one argument - the date in YYYYMMDD format. Your testing works at the command-line, but you now need to implement this into your Airflow DAG. For now, use the term {{ ds_nodash }} in your template - you'll see exactly what this is means later on."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from datetime import datetime\n",
    "\n",
    "default_args = {\n",
    "  'start_date': datetime(2020, 4, 15),\n",
    "}\n",
    "\n",
    "cleandata_dag = DAG('cleandata',\n",
    "                    default_args=default_args,\n",
    "                    schedule_interval='@daily')\n",
    "\n",
    "# Create a templated command to execute\n",
    "templated_command =\"\"\"\n",
    "bash cleandata.sh {{ ds_nodash }}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Modify clean_task to use the templated command\n",
    "clean_task = BashOperator(task_id='cleandata_task',\n",
    "                          bash_command=templated_command,\n",
    "                          dag=cleandata_dag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You've successfully modified the DAG to use a templated command instead of hardcoding your workflow objects. This will come in very handy when creating production workflows. Note that for now, we didn't need to define a params argument in the BashOperator - this is ok as Airflow handles passing some data into templates automatically for us."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Templates with multiple arguments\n",
    "You wish to build upon your previous DAG and modify the code to support two arguments - the date in YYYYMMDD format, and a file name passed to the cleandata.sh script."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Task(BashOperator): cleandata_task>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from datetime import datetime\n",
    "\n",
    "default_args = {\n",
    "  'start_date': datetime(2020, 4, 15),\n",
    "}\n",
    "\n",
    "cleandata_dag = DAG('cleandata',\n",
    "                    default_args=default_args,\n",
    "                    schedule_interval='@daily')\n",
    "\n",
    "# Modify the templated command to handle a\n",
    "# second argument called filename.\n",
    "templated_command = \"\"\"\n",
    "  bash cleandata.sh {{ ds_nodash }} {{ params.filename }}\n",
    "\"\"\"\n",
    "\n",
    "# Modify clean_task to pass the new argument\n",
    "clean_task = BashOperator(task_id='cleandata_task',\n",
    "                          bash_command=templated_command,\n",
    "                          params={'filename': 'salesdata.txt'},\n",
    "                          dag=cleandata_dag)\n",
    "\n",
    "# Create a new BashOperator clean_task2\n",
    "clean_task2 = BashOperator(task_id='cleandata_task2',\n",
    "                          bash_command=templated_command,\n",
    "                          params={'filename': 'supportdata.txt'},\n",
    "                          dag=cleandata_dag)\n",
    "\n",
    "# Set the operator dependencies\n",
    "clean_task2 << clean_task"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making use of multiple operators that vary by the parameters is a great use of templated commands in Airflow!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using lists with templates\n",
    "Once again, you decide to make some modifications to the design of your cleandata workflow. This time, you realize that you need to run the command cleandata.sh with the date argument and the file argument as before, except now you have a list of 30 files. You do not want to create 30 tasks, so your job is to modify the code to support running the argument for 30 or more files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from datetime import datetime\n",
    "\n",
    "filelist = [f'file{x}.txt' for x in range(30)]\n",
    "\n",
    "default_args = {\n",
    "  'start_date': datetime(2020, 4, 15),\n",
    "}\n",
    "\n",
    "cleandata_dag = DAG('cleandata',\n",
    "                    default_args=default_args,\n",
    "                    schedule_interval='@daily')\n",
    "\n",
    "# Modify the template to handle multiple files in a\n",
    "# single run.\n",
    "templated_command = \"\"\"\n",
    "  <% for filename in params.filenames %>\n",
    "  bash cleandata.sh {{ ds_nodash }} {{ filename }};\n",
    "  <% endfor %>\n",
    "\"\"\"\n",
    "\n",
    "# Modify clean_task to use the templated command\n",
    "clean_task = BashOperator(task_id='cleandata_task',\n",
    "                          bash_command=templated_command,\n",
    "                          params={'filenames': filelist},\n",
    "                          dag=cleandata_dag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You've successfully implemented a Jinja template to iterate over the files in a list and execute a bash command for each file. This type of flexibility and power provides a lot of options to best configure a workflow using Airflow."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Understanding parameter options\n",
    "You've used a few different methods to add templates to your workflows. Considering the differences between options, why would you want to create individual tasks (ie, BashOperators) with specific parameters vs a list of files?\n",
    "\n",
    "For example, why would you choose\n",
    "```python\n",
    "t1 = BashOperator(task_id='task1', bash_command=templated_command, params={'filename': 'file1.txt'}, dag=dag)\n",
    "t2 = BashOperator(task_id='task2', bash_command=templated_command, params={'filename': 'file2.txt'}, dag=dag)\n",
    "t3 = BashOperator(task_id='task3', bash_command=templated_command, params={'filename': 'file3.txt'}, dag=dag)\n",
    "```\n",
    "over using a loop form such as\n",
    "```python\n",
    "t1 = BashOperator(task_id='task1',\n",
    "                  bash_command=templated_command,\n",
    "                  params={'filenames': ['file1.txt', 'file2.txt', 'file3.txt']},\n",
    "                  dag=dag)\n",
    "```\n",
    "\n",
    "Using specific tasks allows better monitoring of task state and possible parallel execution. When using a single task,\n",
    "all entries would succeed or fail as a single task. Separate operators allow for better monitoring and scheduling of\n",
    "these tasks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sending templated emails\n",
    "While reading through the Airflow documentation, you realize that various operations can use templated fields to provide added flexibility. You come across the docs for the EmailOperator and see that the content can be set to a template. You want to make use of this functionality to provide more detailed information regarding the output of a DAG run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from airflow.models import DAG\n",
    "from airflow.operators.email_operator import EmailOperator\n",
    "from datetime import datetime\n",
    "\n",
    "# Create the string representing the html email content\n",
    "html_email_str = \"\"\"\n",
    "Date: {{ ds }}\n",
    "Username: {{ params.username }}\n",
    "\"\"\"\n",
    "\n",
    "email_dag = DAG('template_email_test',\n",
    "                default_args={'start_date': datetime(2020, 4, 15)},\n",
    "                schedule_interval='@weekly')\n",
    "\n",
    "email_task = EmailOperator(task_id='email_task',\n",
    "                           to='testuser@datacamp.com',\n",
    "                           subject=\"{{ macros.uuid.uuid4() }}\",\n",
    "                           html_content=html_email_str,\n",
    "                           params={'username': 'testemailuser'},\n",
    "                           dag=email_dag)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As mentioned, there are many operators that can accept templated fields. When browsing the documentation, if a field is referred to as templated, it can use these techniques.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}